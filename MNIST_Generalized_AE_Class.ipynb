{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Generalized AE Class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNlEX2RpqEoAS3hkulk5sAV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vz415/AE32D_optimization/blob/master/MNIST_Generalized_AE_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3l8K2xV-xlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting classy\n",
        "# import the necessary packages\n",
        "# from tensorflow.keras.layers import LeakyReLU\n",
        "# from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from keras import regularizers\n",
        "# from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "class flatAutoencoder:\n",
        "  @staticmethod\n",
        "  def build(input_shape, layer_dims=(512, 256, 128, 32), \n",
        "            enc_dropout_reg = None, dec_dropout_reg = None,\n",
        "            enc_l2_reg = None, dec_l2_reg = None,\n",
        "            enc_l1_reg = None, dec_l1_reg = None):\n",
        "    '''\n",
        "    enc_dropout_reg: takes tuple size of layer_dims and with the desired dropout\n",
        "    in the correct index following encoding layer. e.g. (0.5,None,None) if a \n",
        "    dropout of 0.5 is desired after the initial layer in given default layer_dims.\n",
        "    dec_dropout_reg: takes tuple size of layer_dims and desired dropout in \n",
        "    index following decoder layers. e.g.(0.5,None,None) in given default\n",
        "    layer_dims. Currently can't do the last layer but that's small as most models\n",
        "    performed worse with that layer.\n",
        "\n",
        "    enc_l2_reg: l2 regularization added to encoder layers if specified. Takes a \n",
        "    tuple e.g. (10e-5, None, None) for regularization of the corresponding layer.\n",
        "    dec_l2_reg: l2 regularization added to decoder layers if specified. Takes a \n",
        "    tuple e.g. (10e-5, None, None) for regularization of the corresponding layer.\n",
        "\n",
        "    enc_l1_reg: l1 regularization added to encoder layers if specified. Takes a \n",
        "    tuple e.g. (10e-5, None, None) for regularization of the corresponding layer.\n",
        "    dec_l1_reg: l1 regularization added to decoder layers if specified. Takes a \n",
        "    tuple e.g. (10e-5, None, None) for regularization of the corresponding layer.\n",
        "    '''\n",
        "    # define the input to the encoder\n",
        "    inputs = Input(shape=(input_shape,))\n",
        "    x = inputs\n",
        "\n",
        "\t\t# loop over the number of layer_dims to add sets of layers\n",
        "    for i, dim in enumerate(layer_dims):\n",
        "      # Check l2 regularization\n",
        "      if enc_l2_reg is not None:\n",
        "        if enc_l2_reg[i]:\n",
        "          x = Dense(dim, activation='relu', \n",
        "                    activity_regularizer=regularizers.l2(enc_l2_reg[i]))(x)\n",
        "        else:\n",
        "          x = Dense(dim, activation='relu', \n",
        "                      activity_regularizer=None)(x)\n",
        "      \n",
        "      # Check l1 regularization\n",
        "      elif enc_l1_reg is not None:\n",
        "        if enc_l1_reg[i]:\n",
        "          x = Dense(dim, activation='relu', \n",
        "                    activity_regularizer=regularizers.l1(enc_l1_reg[i]))(x)\n",
        "        else:\n",
        "          x = Dense(dim, activation='relu', \n",
        "                      activity_regularizer=None)(x)\n",
        "\n",
        "      # Non-regularized layer if no l2/l1\n",
        "      else:\n",
        "        x = Dense(dim, activation='relu', \n",
        "                      activity_regularizer=None)(x)\n",
        "\n",
        "      # Introduce dropout if specified\n",
        "      if enc_dropout_reg is not None:\n",
        "        if enc_dropout_reg[i]:\n",
        "          x = Dropout(enc_dropout_reg[i])(x)\n",
        "    \n",
        "    # build encoder model\n",
        "    encoder = Model(inputs, x, name=\"encoder\")\n",
        "    \n",
        "    # Building decoder model\n",
        "    latentInputs = Input(shape=(layer_dims[-1],))\n",
        "    x = latentInputs\n",
        "\n",
        "    # loop over our number of layer_dims again, but in reverse order\n",
        "    for i, dim in reversed(list(enumerate(layer_dims[:-1]))):\n",
        "      # Introduce dropout if specified\n",
        "      if dec_dropout_reg is not None:\n",
        "        if dec_dropout_reg[i]:\n",
        "          x = Dropout(dec_dropout_reg[i])(x)\n",
        "\n",
        "      # Check l2 regularization\n",
        "      if dec_l2_reg is not None:\n",
        "        if dec_l2_reg[i]:\n",
        "          x = Dense(dim, activation='relu', \n",
        "                    activity_regularizer=regularizers.l2(dec_l2_reg[i]))(x)\n",
        "        else:\n",
        "          x = Dense(dim, activation='relu', \n",
        "                      activity_regularizer=None)(x)\n",
        "      \n",
        "      # Check l1 regularization\n",
        "      elif dec_l1_reg is not None:\n",
        "        if dec_l1_reg[i]:\n",
        "          x = Dense(dim, activation='relu', \n",
        "                    activity_regularizer=regularizers.l1(dec_l1_reg[i]))(x)\n",
        "        else:\n",
        "          x = Dense(dim, activation='relu', \n",
        "                      activity_regularizer=None)(x)\n",
        "\n",
        "      # Non-regularized layer if no l2/l1\n",
        "      else:\n",
        "        x = Dense(dim, activation='relu', \n",
        "                      activity_regularizer=None)(x)\n",
        "      # x = LeakyReLU(alpha=0.2)(x) -> might want to try this out later\n",
        "      \n",
        "    # apply linear activation (in this case) for output\n",
        "    outputs = Dense(input_shape, activation='linear')(x)\n",
        "    \n",
        "    # build the decoder model\n",
        "    decoder = Model(latentInputs, outputs, name=\"decoder\")\n",
        "\n",
        "    # autoencoder is the encoder wrapped by decoder\n",
        "    autoencoder = Model(inputs, decoder(encoder(inputs)),\n",
        "                        name=\"autoencoder\")\n",
        "\n",
        "    # return a 3-tuple of the encoder, decoder, and autoencoder\n",
        "    return (encoder, decoder, autoencoder)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoB0j62_mXhG",
        "colab_type": "text"
      },
      "source": [
        "TODO:\n",
        "1. ~Create method to integrate regularization into encoding or decoding layer~\n",
        "2. ~Fix error that makes layers smaller for some reason (see below layer summaries)~\n",
        "3. ~Change layer_dims so that it includes the encoding dimension to simplify the code. Ridiculous that I would need to make a special argument just for the encoding dimension - it's the smallest layer. Just use that info.~\n",
        "4. ~Verify that regularization is built into the layer~\n",
        "5. Automatic file saving during training.\n",
        "\n",
        "Future work:\n",
        "1. Make tests for if more dropouts are provided than can be used\n",
        "2. Create error if regularization are put in the same spot in the network - e.g. whenever the tupes for both l1 and l2 encoder regularzation are the same\n",
        "3. Allow different outputs from the model, such as softmax\n",
        "4. Implement elastic net regularization\n",
        "5. Create optional argument to share parameters betwee encoding/decoding layers\n",
        "6. Fix dropout tuple length error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTQeLSM_QzCE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d862319a-9946-4f87-e867-dc81a518c8d9"
      },
      "source": [
        "layer_dims=(512, 256, 128, 32)\n",
        "# layer_dims + layer_dims[::-1][1:]\n",
        "'-'.join(str(v) for v in layer_dims[:-1] + layer_dims[::-1])\n",
        "# print([str(x)+'-' for x in layer_dims[:-1]])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'512-256-128-32-128-256-512'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSlOSYi7e8ES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fe6ac14-a908-48e2-97ab-3c1143ed5a4b"
      },
      "source": [
        "layer_dims=(512, 256, 128, 32)\n",
        "enc_dropout_reg = (0.5,0.4,0.3,0.2)\n",
        "dec_dropout_reg = (0.5,0.5,0.5,0.5)\n",
        "enc_l2_reg = (1e-1,1e-1,1e-1,1e-1)\n",
        "dec_l2_reg = (1e-2,1e-2,1e-2,1e-2)\n",
        "# enc_l1_reg = (1e-3,1e-3,1e-3,1e-3)\n",
        "enc_l1_reg = (None,None,None,None)\n",
        "# dec_l1_reg = (1e-4,1e-4,1e-4,1e-4)\n",
        "dec_l1_reg = (None,None,None,None)\n",
        "\n",
        "# Think I'm going to need to zip forward/backward direction items together\n",
        "forward_pass = list(zip(layer_dims[:-1], enc_l1_reg, enc_l2_reg, enc_dropout_reg))\n",
        "forward_pass\n",
        "backward_pass = list(zip(layer_dims[::-1], dec_l1_reg, dec_l2_reg, dec_dropout_reg))\n",
        "backward_pass"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(512, None, 0.1, 0.5), (256, None, 0.1, 0.4), (128, None, 0.1, 0.3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJCTPEIigswa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9cb32e5c-e81c-4bb3-8ff6-00c7704949a2"
      },
      "source": [
        "dummy = []\n",
        "for forward_layer in forward_pass:\n",
        "  dummy.append('-'.join(str(v) for v in forward_layer))\n",
        "forward_name = '_'.join(str(v) for v in dummy)\n",
        "\n",
        "dummy2 = []\n",
        "for backward_layer in backward_pass:\n",
        "  dummy2.append('-'.join(str(v) for v in backward_layer))\n",
        "backward_name = '_'.join(str(v) for v in dummy2)\n",
        "\n",
        "'_'.join((forward_name, backward_name))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'512-None-0.1-0.5_256-None-0.1-0.4_128-None-0.1-0.3_32-None-0.01-0.5_128-None-0.01-0.5_256-None-0.01-0.5_512-None-0.01-0.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1FpYZtnOnMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ecb3d5e-c29f-48e6-9ee9-7d6017137493"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "date = datetime.today().strftime('%Y-%m-%d')\n",
        "study_name = \"Example\"\n",
        "optimizer_metric = \"RMS_prop-MSE\"\n",
        "\n",
        "layer_dims=(512, 256, 128, 32)\n",
        "enc_dropout_reg = (None,None,None,None)\n",
        "dec_dropout_reg = (None,None,None,None)\n",
        "enc_l2_reg = (None,None,None,None)\n",
        "dec_l2_reg = (None,None,None,None)\n",
        "enc_l1_reg = (None,None,None,None)\n",
        "dec_l1_reg = (None,None,None,None)\n",
        "\n",
        "layer_file = '-'.join(str(v) for v in layer_dims)\n",
        "\n",
        "(encoder, decoder, autoencoder) = flatAutoencoder.build(1728, layer_dims=layer_dims,\n",
        "                                      enc_dropout_reg=enc_dropout_reg, \n",
        "                                      dec_dropout_reg=dec_dropout_reg,\n",
        "                                      enc_l2_reg=enc_l2_reg,\n",
        "                                      dec_l1_reg=dec_l1_reg)\n",
        "\n",
        "# Configuring optimizer and loss function\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.001, momentum=0)\n",
        "autoencoder.compile(optimizer=opt, \n",
        "                    loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "# Path library\n",
        "file_path = \"./drive/My Drive/Lab/BMP AE Models/Models/{} AE/{}/{}/{}\".format(layer_file, \n",
        "                                                                               study_name, \n",
        "                                                                               date, \n",
        "                                                                               optimizer_metric)\n",
        "pathlib.Path(file_path).mkdir(parents=True, exist_ok=True)\n",
        "drive_file = file_path + '/AE_drop0-05_512_256_L1-0-1e-4_128_32_128_drop0-05_256_512_model.h5'\n",
        "\n",
        "# Early stopping and checkpointing\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=6000)\n",
        "mc = ModelCheckpoint(filepath=drive_file, \n",
        "                     monitor='val_loss', mode='min', \n",
        "                     verbose=0, save_best_only=False) # Don't only save best\n",
        "csv_logger = CSVLogger(drive_file[:-3]+'history_log.csv', append=True)\n",
        "\n",
        "# Train for 50 epochs\n",
        "history = autoencoder.fit(x_train, x_train,\n",
        "                          epochs=40000,\n",
        "                          batch_size=512,\n",
        "                          shuffle=True,\n",
        "                          validation_data=(x_test, x_test),\n",
        "                          callbacks=[es, mc, csv_logger])\n",
        "\n",
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "print(autoencoder.summary())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "256\n",
            "512\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        [(None, 1728)]            0         \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 512)               885248    \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 32)                4128      \n",
            "=================================================================\n",
            "Total params: 1,053,600\n",
            "Trainable params: 1,053,600\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_24 (InputLayer)        [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 128)               4224      \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 1728)              886464    \n",
            "=================================================================\n",
            "Total params: 1,055,296\n",
            "Trainable params: 1,055,296\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        [(None, 1728)]            0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 32)                1053600   \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 1728)              1055296   \n",
            "=================================================================\n",
            "Total params: 2,108,896\n",
            "Trainable params: 2,108,896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW3rBWP_ZGB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "44925bca-7964-4f92-a548-68e42edb8761"
      },
      "source": [
        "for layer in encoder.layers:\n",
        "  # print(layer)\n",
        "  print(layer.get_config())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_input_shape': (None, 1728), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_14'}\n",
            "{'name': 'dense_48', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'dropout_31', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}\n",
            "{'name': 'dense_49', 'trainable': True, 'dtype': 'float32', 'units': 256, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 3.0}}, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'dropout_32', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}\n",
            "{'name': 'dense_50', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 6.0}}, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'dropout_33', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}\n",
            "{'name': 'dense_51', 'trainable': True, 'dtype': 'float32', 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 69.0}}, 'kernel_constraint': None, 'bias_constraint': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niY2urbr1_8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "ace4df22-c797-4e26-e302-1d1a13660530"
      },
      "source": [
        "for layer in decoder.layers:\n",
        "  # print(layer)\n",
        "  print(layer.get_config())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_input_shape': (None, 32), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_6'}\n",
            "{'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}\n",
            "{'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': {'class_name': 'L1L2', 'config': {'l1': 9.999999747378752e-05, 'l2': 0.0}}, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}\n",
            "{'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 256, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': {'class_name': 'L1L2', 'config': {'l1': 4.0, 'l2': 0.0}}, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}\n",
            "{'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': {'class_name': 'L1L2', 'config': {'l1': 5.0, 'l2': 0.0}}, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 1728, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5BELDAkbfyW",
        "colab_type": "text"
      },
      "source": [
        "I really should look into making a CNN for this. So many less parameters with the CNN.\n",
        "\n",
        "I now need to:\n",
        "1. figure out how to choose where and what type of regularization occurs for each layer. The logic of the for loop is going to get a little more complicated by having "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_DYcpOkPsNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2c156186-2d23-4df6-e6ec-ca54f390f0de"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvRDI34NPsLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "08ed6ea6-b76b-45f7-89a5-e9c592c6c4db"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu',\n",
        "                activity_regularizer=None)(input_img)\n",
        "encoded = Dropout(0.4)(encoded)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "\n",
        "autoencoder.summary()\n",
        "\n",
        "# autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "# autoencoder.fit(x_train, x_train,\n",
        "#                 epochs=50,\n",
        "#                 batch_size=256,\n",
        "#                 shuffle=True,\n",
        "#                 validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 784)               25872     \n",
            "=================================================================\n",
            "Total params: 50,992\n",
            "Trainable params: 50,992\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEyYjdz9PsJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CvNHfwzPsHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHmocEX9PsEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz5xc92nPsAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650z3vfxPr-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4CqJMLwPr9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJgFlEIfPr6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgRSdr2uPr4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWBfoSmOPr2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZXzgz_oPrzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}